# Certificates
This repository contains the Coursera specializations certificates that I have passed during my self-training in Machine Learning field. 

## [Big Data Specializaion](https://www.coursera.org/specializations/big-data)
This Specialization aims to understand big data and how it will impact your business. I gained an understanding of what insights big data can provide through hands-on experience with the tools and systems used by big data scientists and engineers. I have been guided through the basics of using Hadoop with MapReduce, Spark, Pig and Hive. By following along with provided code, I have experienced how one can perform predictive modeling and leverage graph analytics to model problems. This specialization prepared me to ask the right questions about data, communicate effectively with data scientists, and do basic exploration of large, complex datasets. In the final Capstone Project, developed in partnership with data software company Splunk, I applied the skills I learned to do basic analyses of big data.
## [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)
The Deep Learning Specialization is a foundational program that helped me understand the capabilities, challenges, and consequences of deep learning and prepare me to participate in the development of leading-edge AI technology. 

In this specialization, I was able to:
- Build and train deep neural networks, implement vectorized neural networks, identify architecture parameters, and apply DL to your applications
- Use best practices to train and develop test sets and analyze bias/variance for building DL applications, use standard NN techniques, apply optimization algorithms, and implement a neural network in TensorFlow
- Use strategies for reducing errors in ML systems, understand complex ML settings, and apply end-to-end, transfer, and multi-task learning
- Build a Convolutional Neural Network, apply it to visual detection and recognition tasks, use neural style transfer to generate art, and apply these algorithms to image, video, and other 2D/3D data
- Build and train Recurrent Neural Networks and its variants (GRUs, LSTMs), apply RNNs to character-level language modeling, work with NLP and Word Embeddings, and use HuggingFace tokenizers and transformers to perform Named Entity Recognition and Question Answering
## [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning)
This Specialization from leading researchers at the University of Washington introduced me to the exciting, high-demand field of Machine Learning. Through a series of practical case studies, I have gained applied experience in major areas of Machine Learning including Prediction, Classification, Clustering, and Information Retrieval. I have learned to analyze large and complex datasets, create systems that adapt and improve over time, and build intelligent applications that can make predictions from data by using Python programming language. 
## [Tensorflow Specialization](https://www.coursera.org/professional-certificates/tensorflow-in-practice)
TensorFlow is an end-to-end open-source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML, and developers easily build and deploy ML-powered applications. TensorFlow is commonly used for machine learning applications such as voice recognition and detection, Google Translate, image recognition, and natural language processing.

The DeepLearning.AI TensorFlow Developer Professional Certificate program taught me applied machine learning skills with TensorFlow so I can build and train powerful models. This program can help me prepare for the Google TensorFlow Certificate exam and bring me one step closer to achieving the Google TensorFlow Certificate. 

In this Specialization, I was able to: 
- Build and train neural networks using TensorFlow
- Improve your networkâ€™s performance using convolutions as you train it to identify real-world images
- Teach machines to understand, analyze, and respond to human speech with natural language processing systems
- Process text, represent sentences as vectors, and train a model to create original poetry!
## [Tensorflow Advanced Specialization](https://www.coursera.org/specializations/tensorflow-advanced-techniques)
This Specialization is for software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge of the Functional API and build exotic non-sequential model types. Learn how to optimize training in different environments with multiple processors and chip types and get introduced to advanced computer vision scenarios such as object detection, image segmentation, and interpreting convolutions. Explore generative deep learning including the ways AIs can create new content from Style Transfer to Auto Encoding, VAEs, and GANs.

In this specialization, I was able to:
- Understand the underlying basis of the Functional API and build exotic non-sequential model types, custom loss functions, and layers. 
- Learn how optimization works and how to use GradientTape and Autograph. Optimize training in different environments with multiple processors and chip types
- Practice object detection, image segmentation, and visual interpretation of convolutions
- Explore generative deep learning and how AIs can create new content, from Style Transfer through Auto Encoding and VAEs to Generative Adversarial Networks
## [MLOps Specialization](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)
The Machine Learning Engineering for Production (MLOps) Specialization covers how to conceptualize, build, and maintain integrated systems that continuously operate in production. In striking contrast with standard machine learning modeling, production systems need to handle relentless evolving data. Moreover, the production system must run non-stop at the minimum cost while producing the maximum performance. In this Specialization, you will learn how to use well-established tools and methodologies for doing all of this effectively and efficiently.

In this specialization, I was able to:
- Design an ML production system end-to-end: project scoping, data needs, modeling strategies, and deployment requirements
- Establish a model baseline, address concept drift, and prototype how to develop, deploy, and continuously improve a productionized ML application
- Build data pipelines by gathering, cleaning, and validating datasets
- mplement feature engineering, transformation, and selection with TensorFlow Extended
- Establish data lifecycle by leveraging data lineage and provenance metadata tools and follow data evolution with enterprise data schemas
- Apply techniques to manage modeling resources and best serve offline/online inference requests
- Use analytics to address model fairness, explainability issues, and mitigate bottlenecks
- Deliver deployment pipelines for model serving that require different infrastructures
- Apply best practices and progressive delivery techniques to maintain a continuously operating production system
